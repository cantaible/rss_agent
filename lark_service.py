# FastAPI æ˜¯ web æ¡†æ¶
from fastapi import FastAPI
import uvicorn
import json
from fastapi import BackgroundTasks, Request
from contextlib import asynccontextmanager

from agent_graph import graph
from langchain_core.messages import HumanMessage
from messaging import reply_message
from apscheduler.schedulers.background import BackgroundScheduler
from datetime import date
from database import save_cached_news, get_cached_news, DB_FILE, upsert_preference, init_db
import sqlite3
import asyncio
import threading
from pytz import timezone
from collections import deque

# äº‹ä»¶å»é‡é˜Ÿåˆ—
processed_events = deque(maxlen=100)

# åˆå§‹åŒ–è°ƒåº¦å™¨ï¼ˆä½¿ç”¨åŒ—äº¬æ—¶åŒºï¼‰
beijing_tz = timezone('Asia/Shanghai')
scheduler = BackgroundScheduler(timezone=beijing_tz)
daily_archive_push_lock = threading.Lock()

# def pre_generate_daily_news():
#     """(å·²å¼ƒç”¨) æ¯å¤©9ç‚¹ï¼šé¢„ç”Ÿæˆ4ä¸ªç±»åˆ«çš„æ—©æŠ¥"""
#     pass

# --- ä»»åŠ¡åˆ†ç¦»ï¼šç”Ÿæˆä¸æ¨é€ ---

from config import DAILY_NEWS_CATEGORIES

def generate_news_task(force=True):
    """
    ğŸ‘¨â€ğŸ³ å¨å¸ˆä»»åŠ¡ï¼šæ¯éš”2å°æ—¶ï¼ˆæˆ–å¯åŠ¨æ—¶ï¼‰ç”Ÿæˆæ–°é—»å¹¶å­˜å…¥æ•°æ®åº“ï¼ˆä¸æ¨é€ï¼‰
    
    æ”¹è¿›ï¼šç›´æ¥ä» config.py è¯»å–ç±»åˆ«ï¼Œä½œä¸ºå‚æ•°ä¼ é€’ç»™ agentï¼Œä¸ä¾èµ–æ•°æ®åº“æŸ¥è¯¢
    """
    today = date.today().isoformat()
    
    print(f"ğŸ‘¨â€ğŸ³ [Chef] Starting news generation (Force={force}) for categories: {DAILY_NEWS_CATEGORIES}...")

    for category in DAILY_NEWS_CATEGORIES:
        # å…³é”®ä¿®å¤ï¼šæ¯ä¸ªç±»åˆ«ä½¿ç”¨ç‹¬ç«‹çš„ thread_idï¼Œé¿å… LangGraph state æ±¡æŸ“
        # ä¾‹å¦‚: system_daily_bot_AI, system_daily_bot_GAMES, system_daily_bot_MUSIC
        category_user_id = f"system_daily_bot_{category}"
        
        # å¦‚æœä¸æ˜¯å¼ºåˆ¶åˆ·æ–° (å³ Startup æ¨¡å¼)ï¼Œå…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰é¥­èœ
        if not force:
            cached = get_cached_news(category, today)
            if cached:
                print(f"â© [Chef] Data exists for {category}, skipping generation (Startup check).")
                continue

        try:
            # 1. ç”Ÿæˆæ–°é—»
            # å…³é”®æ”¹åŠ¨ï¼šç›´æ¥ä¼ å…¥ user_preference=categoryï¼Œè·³è¿‡ router è§£æå’Œæ•°æ®åº“æŸ¥è¯¢
            # force_refresh=True å¼ºåˆ¶é‡æ–°æŠ“å–æ–°é—»ï¼Œä¸ä½¿ç”¨ç¼“å­˜
            content, briefing_data = run_agent(
                user_id=category_user_id,  # â† ä½¿ç”¨ç‹¬ç«‹çš„ thread_id
                text="ç”Ÿæˆæ—¥æŠ¥",  # æ–‡æœ¬ä¸å†é‡è¦ï¼Œä»…ä½œå ä½
                force_refresh=True,
                user_preference=category  # ç›´æ¥ä¼ å…¥ç±»åˆ«ï¼
            )
            
            # 2. å­˜æ ¹
            if briefing_data:
                briefing_data_str = json.dumps(briefing_data, ensure_ascii=False)
                save_cached_news(category, content, today, briefing_data_str)
                print(f"ğŸ’¾ [Chef] Saved cache for {category}. Ready to serve.")
            else:
                print(f"âš ï¸ [Chef] No data generated for {category}")
                
        except Exception as e:
            print(f"âŒ [Chef] Failed for {category}: {e}")

def push_delivery_task():
    """ğŸ›µ å¤–å–å‘˜ä»»åŠ¡ï¼šæ¨é€æœ€æ–°çš„æ–°é—»"""
    today = date.today().isoformat()
    conn = sqlite3.connect(DB_FILE)
    users = conn.execute("SELECT user_id, category FROM user_preferences").fetchall()
    conn.close()
    
    from messaging import send_message
    
    print(f"ğŸ›µ [Delivery] Starting daily push dispatch...")
    
    for user_id, category in users:
        # 1. åªæ˜¯å»å–è´§
        cached_data = get_cached_news(category, today)
        
        if cached_data and cached_data.get("content"):
            print(f"ğŸ“¤ [Delivery] Pushing hot news to {user_id}")
            send_message(user_id, cached_data["content"])
        else:
            print(f"âš ï¸ [Delivery] No food ready for {user_id} (Cache miss)")
            # å¯é€‰ï¼šè¿™é‡Œå¯ä»¥è§¦å‘ä¸€æ¬¡ generate_news_task() ä½œä¸ºè¡¥æ•‘

def daily_archive_and_push_job():
    """ç»Ÿä¸€å®šæ—¶ä»»åŠ¡ï¼šå…ˆå½’æ¡£ï¼Œå†æ¨é€ã€‚"""
    if not daily_archive_push_lock.acquire(blocking=False):
        print("â© [Scheduler] daily_archive_and_push_job is already running, skipping this trigger.")
        return

    try:
        print("â° [Scheduler] Starting daily archive + push job...")
        try:
            asyncio.run(archive_daily_news_to_wiki(user_id=None, notify_user=False))
        except Exception as e:
            print(f"âŒ [Scheduler] Archive step failed: {e}")

        push_delivery_task()
        print("âœ… [Scheduler] Finished daily archive + push job.")
    finally:
        daily_archive_push_lock.release()

# ä½¿ç”¨ FastAPI æ¨èçš„ lifespan æ–¹å¼ï¼ˆç”¨äºä¼˜é›…å…³é—­å’Œé¿å…é‡å¤åˆå§‹åŒ–ï¼‰
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup - åªåœ¨ worker è¿›ç¨‹ä¸­æ‰§è¡Œï¼ˆé¿å… reload æ¨¡å¼ä¸‹çš„é‡å¤åˆå§‹åŒ–ï¼‰
    print("ğŸ“¦ Initializing database...")
    init_db()
    
    print("â° Starting Scheduler...")
    from datetime import datetime, timedelta
    
    # 1. å¨å¸ˆä»»åŠ¡ï¼šåŒ—äº¬æ—¶é—´ 8:00 - 22:00ï¼Œæ¯2å°æ—¶åšä¸€æ¬¡é¥­
    scheduler.add_job(generate_news_task, 'cron', hour='8-22/2', minute=0, timezone=beijing_tz)
    
    # 2. ä¹Ÿæ˜¯å¨å¸ˆä»»åŠ¡ï¼šåˆšå¼€ä¸šï¼ˆå¯åŠ¨æœåŠ¡ï¼‰æ—¶å…ˆåšä¸€é¡¿
    # å…³é”®ï¼šè¿™é‡Œ force=Falseï¼Œå¦‚æœæ•°æ®åº“é‡Œå·²ç»æœ‰èœäº†ï¼Œå°±ä¸é‡åšäº† (é¿å…çƒ­é‡è½½æ—¶ç–¯ç‹‚ç”Ÿæˆ)
    scheduler.add_job(generate_news_task, 'date', run_date=datetime.now(beijing_tz) + timedelta(seconds=5), kwargs={"force": False})
    
    # 3. ç»Ÿä¸€ä»»åŠ¡ï¼šåŒ—äº¬æ—¶é—´æ¯å¤© 09:10ï¼Œå…ˆå½’æ¡£å†æ¨é€
    scheduler.add_job(
        daily_archive_and_push_job,
        'cron',
        id='daily_archive_and_push_job',
        hour=9,
        minute=10,
        timezone=beijing_tz,
        replace_existing=True,
        max_instances=1,
        coalesce=True,
    )
    
    scheduler.start()
    print(f"âœ… Scheduler started with timezone: {beijing_tz}")
    
    yield
    
    # Shutdown (ä¼˜é›…å…³é—­è°ƒåº¦å™¨)
    print("ğŸ›‘ Shutting down scheduler...")
    scheduler.shutdown()

# åˆ›å»ºä¸€ä¸ª App å®ä¾‹ï¼Œä½¿ç”¨ lifespan
app = FastAPI(lifespan=lifespan)

def run_agent(user_id, text, message_id=None, force_refresh=False, user_preference=None):
    """
    è¿è¡Œ LangGraph Agent
    
    å‚æ•°:
        user_id: ç”¨æˆ·ID
        text: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
        message_id: æ¶ˆæ¯IDï¼ˆç”¨äºå›å¤ï¼‰
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
        user_preference: ç›´æ¥æŒ‡å®šç”¨æˆ·åå¥½ç±»åˆ«ï¼ˆå®šæ—¶ä»»åŠ¡ä¸“ç”¨ï¼Œè·³è¿‡ router å’Œæ•°æ®åº“æŸ¥è¯¢ï¼‰
    """
    config = {"configurable": {"thread_id": user_id}}
    
    # è·å–å†å²æ¶ˆæ¯ï¼ˆç”¨äºèŠå¤©æ¨¡å¼çš„ä¸Šä¸‹æ–‡è®°å¿†ï¼‰
    try:
        previous_state = graph.get_state(config)
        history = previous_state.values.get("messages", []) if previous_state and previous_state.values else []
    except Exception:
        history = []
    
    # æ»‘åŠ¨çª—å£ï¼šåªä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯ï¼ˆçº¦5è½®å¯¹è¯ï¼‰ï¼Œé¿å…è¶… Token é™é¢
    recent_history = history[-10:] if len(history) > 10 else history
    
    # æ‹¼æ¥å†å² + æ–°æ¶ˆæ¯
    inputs = {
        "messages": recent_history + [HumanMessage(content=text)], 
        "user_id": user_id,
        "message_id": message_id,
        "force_refresh": force_refresh, # [æ–°å¢] æ§åˆ¶æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
        "user_preference": user_preference # [æ–°å¢] ç›´æ¥ä¼ å…¥åå¥½ç±»åˆ«
    }
    
    # ä¼ å…¥ thread_id ä»¥å¯ç”¨ state æŒä¹…åŒ–ï¼ˆæ¯ä¸ªç”¨æˆ·ç‹¬ç«‹å­˜å‚¨ï¼‰
    res = graph.invoke(inputs, config=config)
    
    # è¿”å› (content, briefing_data)
    content = res["messages"][-1].content
    briefing_data = res.get("briefing_data")
    return content, briefing_data

# å®šä¹‰ä¸€ä¸ª GET æ¥å£ï¼Œè®¿é—®æ ¹è·¯å¾„ "/" æ—¶è§¦å‘
@app.get("/")
def health_check():
    return {"status": "ok", "message": "Bot is running! (æœºå™¨äººæ­£åœ¨è¿è¡Œ)"}

# å¼‚æ­¥åå°ä»»åŠ¡ï¼šAI æ€è€ƒå¹¶å›å¤
def process_lark_message(event_data):
    message_id = event_data["message"]["message_id"]
    content_json = event_data["message"]["content"]
    user_text = json.loads(content_json)["text"]
    
    # æå–å‘é€è€… ID
    sender_id = event_data["sender"]["sender_id"]["open_id"]
    
    # AI æ€è€ƒ (ä¼ å…¥ ID å’Œ Message ID)
    # run_agent è¿”å› (content, briefing_data)
    ai_reply_content, _ = run_agent(sender_id, user_text, message_id)
    
    # å›å¤
    reply_message(message_id, ai_reply_content)



@app.post("/api/lark/event")
async def handle_event(request: Request, background_tasks: BackgroundTasks):
    # è§£æåŸå§‹ JSON
    body = await request.json()
    
    # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°æ‰€æœ‰æ”¶åˆ°çš„è¯·æ±‚
    print(f"\n{'='*60}")
    print(f"ğŸ“¨ [DEBUG] Received request")
    print(f"Request type: {body.get('type')}")
    print(f"Event type: {body.get('header', {}).get('event_type')}")
    print(f"Full body keys: {list(body.keys())}")
    print(f"Full body keys: {list(body.keys())}")
    print(f"{'='*60}\n")
    
    # 0. å»é‡å¤„ç† (é˜²æ­¢é£ä¹¦è¶…æ—¶é‡è¯•å¯¼è‡´äºŒæ¬¡è§¦å‘)
    event_id = body.get("header", {}).get("event_id")
    if event_id and event_id in processed_events:
        print(f"â© [Event] Duplicate event {event_id}, skipping.")
        return {"code": 0}
    
    if event_id:
        processed_events.append(event_id)
    
    # 1. æ¡æ‰‹éªŒè¯
    if body.get("type") == "url_verification":
        print("âœ… [Verification] Responding to URL verification")
        return {"challenge": body.get("challenge")}
        
    # 2. å¤„ç†ç”¨æˆ·æ¶ˆæ¯ (Event v2 æ ¼å¼)
    if body.get("header", {}).get("event_type") == "im.message.receive_v1":
        print("ğŸ“§ [Message] Processing user message")
        # æ”¾å…¥åå°è¿è¡Œï¼Œä¸é˜»å¡ HTTP è¿”å›
        background_tasks.add_task(process_lark_message, body["event"])

    # [æ–°å¢] å¤„ç†èœå•ç‚¹å‡»äº‹ä»¶
    elif body.get("header", {}).get("event_type") == "application.bot.menu_v6":
        event = body.get("event", {})
        event_key = event.get("event_key", "") # e.g. "subscribe:AI"
        operator_id = event.get("operator", {}).get("operator_id", {}).get("open_id")
        
        print(f"ğŸ”˜ [Menu Event] Key: {event_key}, User: {operator_id}")
        
        if event_key.startswith("subscribe:"):
            category = event_key.split(":")[1]
            upsert_preference(operator_id, category)
            
            # ç”±äºèœå•ç‚¹å‡»æ²¡æœ‰ message_id ä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬éœ€è¦ä¸»åŠ¨å‘æ¶ˆæ¯ç»™ç”¨æˆ·
            # ä½†è¿™é‡Œæ²¡æœ‰ reply tokenï¼Œé€šå¸¸ç›´æ¥è°ƒ send_message
            from messaging import send_message
            send_message(operator_id, f"âœ… å·²æˆåŠŸè®¢é˜… **{category}** ç±»åˆ«ï¼\næˆ‘ä»¬å°†ä¸ºæ‚¨æ¨é€è¯¥ç±»åˆ«çš„æ¯æ—¥æ—©æŠ¥ã€‚")

        # 2. æ–°å¢ï¼šå¤„ç†æ‰‹åŠ¨è§¦å‘æ–°é—»è¯·æ±‚
        elif event_key in ["REQUEST_MUSIC_NEWS", "REQUEST_GAMES_NEWS", "REQUEST_AI_NEWS"]:
            # æå–ç±»åˆ«: REQUEST_MUSIC_NEWS -> MUSIC
            target_category = event_key.split("_")[1] 
            print(f"ğŸ” [Menu] ç”¨æˆ· {operator_id} è¯·æ±‚è·å–ï¼š{target_category} æ–°é—»")
            
            from datetime import date
            today = date.today().isoformat()
            cached = get_cached_news(target_category, today)
            
            from messaging import send_message
            if cached and cached.get("content"):
                send_message(operator_id, cached["content"])
            else:
                send_message(operator_id, f"â„¹ï¸ æŠ±æ­‰ï¼Œä»Šå¤©çš„ã€{target_category}ã€‘æ—¥æŠ¥æš‚æœªç”Ÿæˆã€‚\nè¯·ç¨åå†è¯•ï¼Œæˆ–ç­‰å¾…æ¯æ—¥å®šæ—¶æ¨é€ã€‚")

        # 3. æ–°å¢ï¼šæµ‹è¯•å½’æ¡£åˆ° Wiki
        elif event_key == "WRITE_DAILY_NEWS":
             print(f"ğŸ“ [Menu] ç”¨æˆ· {operator_id} è¯·æ±‚ï¼šå½’æ¡£æ—¥æŠ¥åˆ° Wiki")
             
             from messaging import send_message
             send_message(operator_id, "â³ æ­£åœ¨å°†ä»Šæ—¥å¤šç±»åˆ«æ—¥æŠ¥å½’æ¡£è‡³ Wikiï¼Œè¯·ç¨å€™...")
             
             background_tasks.add_task(archive_daily_news_to_wiki, operator_id)

    # 3. å¤„ç†å¡ç‰‡äº¤äº’ (Card Action)
    # å½“ç”¨æˆ·ç‚¹å‡»å¡ç‰‡æŒ‰é’®æ—¶è§¦å‘
    elif body.get("header", {}).get("event_type") == "card.action.trigger":
        # ä» event å¯¹è±¡ä¸­è·å–æ•°æ®
        event_data = body.get("event", {})
        action_value = event_data.get("action", {}).get("value", {})
        command = action_value.get("command")
        target = action_value.get("target")
        
        # æ„é€ æ¨¡æ‹Ÿçš„æ–‡æœ¬æŒ‡ä»¤ï¼Œä¾‹å¦‚ "å±•å¼€ï¼šç¡¬ä»¶ä¸ç®—åŠ›"
        if command == "expand" and target:
            simulated_text = f"å±•å¼€ï¼š{target}"
            print(f"ğŸƒ [Card Action] Received: {simulated_text}")
            
            # è·å–ç”¨æˆ·å’Œæ¶ˆæ¯ä¸Šä¸‹æ–‡ä¿¡æ¯
            sender_id = event_data.get("operator", {}).get("open_id")
            card_msg_id = event_data.get("context", {}).get("open_message_id")
            
            # åå°å¤„ç†ï¼ˆä¸è¿”å› Toastï¼Œé¿å…3ç§’è¶…æ—¶é™åˆ¶ï¼‰
            background_tasks.add_task(handle_card_action_async, sender_id, simulated_text, card_msg_id, target)
            
            # è¿”å›æˆåŠŸå“åº”ï¼Œä¸æ˜¾ç¤º Toast
            # code:0 è¡¨ç¤ºæˆåŠŸï¼Œtoast.type: info æ˜¾ç¤ºä¸€ä¸ªå°æç¤º
            # å¦‚æœä¸æƒ³æ˜¾ç¤ºä»»ä½•æç¤ºï¼Œå¯ä»¥è¿”å› {"code": 0}ï¼Œæˆ–è€… {"toast": {"type": "success", "content": "æ­£åœ¨å¤„ç†..."}}
            return {"toast": {"type": "info", "content": "æ­£åœ¨ä¸ºæ‚¨åŠ è½½è¯¦æƒ…..."}}
    
    return {"code": 0}

async def handle_card_action_async(user_id, text, message_id, target):
    """å¤„ç†å¡ç‰‡ç‚¹å‡»åçš„å¼‚æ­¥é€»è¾‘"""
    print(f"ğŸƒ [Async] Running agent for card action: {text}")
    
    # ç«‹å³å‘é€"æ­£åœ¨å¤„ç†"æ¶ˆæ¯ï¼Œè®©ç”¨æˆ·çŸ¥é“ç³»ç»Ÿå·²å“åº”
    reply_message(message_id, f"â³ æ­£åœ¨ä¸ºæ‚¨å±•å¼€ **{target}** çš„è¯¦ç»†å†…å®¹ï¼Œè¯·ç¨å€™...")
    
    # åå°æ…¢æ…¢å¤„ç†ï¼ˆæ— 3ç§’é™åˆ¶ï¼‰
    ai_reply_content, _ = run_agent(user_id, text, message_id)
    reply_message(message_id, ai_reply_content)

async def archive_daily_news_to_wiki(user_id=None, notify_user=True):
    """
    åå°ä»»åŠ¡ï¼šå°†ä»Šæ—¥æ—¥æŠ¥å½’æ¡£åˆ° Wiki
    """
    try:
        from doc_writer import FeishuDocWriter
        import os
        from config import WIKI_TOKEN, DAILY_NEWS_CATEGORIES
        
        app_id = os.getenv("LARK_APP_ID")
        app_secret = os.getenv("LARK_APP_SECRET")
        # ç›®æ ‡æ–‡æ¡£: WIKI_TOKEN å·²ä» config å¯¼å…¥ 
        
        if not app_id or not app_secret:
            print("âŒ ç¼ºå°‘ LARK_APP_ID æˆ– LARK_APP_SECRET ç¯å¢ƒå˜é‡")
            return

        print(f"ğŸ“‚ [Archiver] Starting archive task for user {user_id}...")
        
        # 1. å‡†å¤‡æ•°æ®
        today = date.today().isoformat()
        categories = DAILY_NEWS_CATEGORIES
        all_news_data = {}
        
        for cat in categories:
            cached = get_cached_news(cat, today)
            briefing = None
            if cached and cached.get("briefing_data"):
                try:
                    # æ•°æ®åº“é‡Œå­˜çš„æ˜¯ JSON string
                    parsed = json.loads(cached["briefing_data"])
                    if isinstance(parsed, dict):
                        briefing = parsed
                    else:
                        print(f"âš ï¸ {cat} briefing_data ä¸æ˜¯å¯¹è±¡ï¼Œå·²é™çº§ä¸ºæš‚æ— æ•°æ®")
                except Exception as e:
                    print(f"âš ï¸ è§£æ {cat} æ•°æ®å¤±è´¥: {e}")
            
            all_news_data[cat] = briefing
            
        # 2. æ‰§è¡Œå†™å…¥
        writer = FeishuDocWriter(app_id, app_secret)
        success = writer.write_daily_news_to_wiki(WIKI_TOKEN, all_news_data)
        
        # 3. åé¦ˆç”¨æˆ·ï¼ˆå®šæ—¶ä»»åŠ¡å¯å…³é—­é€šçŸ¥ï¼‰
        if success:
            msg = f"âœ… å½’æ¡£æˆåŠŸï¼\nè¯·æŸ¥çœ‹æ–‡æ¡£ï¼š https://bytedance.larkoffice.com/wiki/{WIKI_TOKEN}"
            print("âœ… [Archiver] Archive success.")
        else:
            msg = "âŒ å½’æ¡£å¤±è´¥ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚"
            print("âŒ [Archiver] Archive failed.")

        if notify_user and user_id:
            from messaging import send_message
            send_message(user_id, msg)
        elif notify_user and not user_id:
            print("â„¹ï¸ [Archiver] notify_user=True but user_id is empty, skip sending message.")
        
    except Exception as e:
        print(f"âŒ [Archiver] Exception: {e}")


if __name__ == "__main__":
    # å¯åŠ¨æœåŠ¡å™¨ï¼š
    # "lark_service:app" -> å‘Šè¯‰å¼•æ“å» lark_service.py æ–‡ä»¶é‡Œæ‰¾ app è¿™ä¸ªå˜é‡
    # port=8000 -> ç›‘å¬ 8000 ç«¯å£
    # reload=True -> ä½ ä¸€æ”¹ä»£ç ï¼ŒæœåŠ¡å™¨è‡ªåŠ¨é‡å¯ï¼ˆæ–¹ä¾¿å¼€å‘ï¼‰
    uvicorn.run("lark_service:app", host="0.0.0.0", port=36000, reload=True)
