from typing import TypedDict, List, Optional, Dict
from langchain_core.messages import BaseMessage
from pydantic import BaseModel, Field
from typing import Literal

# --- é•¿åº¦æ§åˆ¶å¸¸é‡ï¼ˆè§†è§‰å®½åº¦ï¼Œ1ä¸­æ–‡å­—=2è‹±æ–‡å­—æ¯ï¼‰ ---
HEADLINE_LENGTH_MIN = 10  # ä»Šæ—¥å¤´æ¡æœ€çŸ­è§†è§‰å®½åº¦ï¼ˆä¸­æ–‡å­—æ•°ï¼‰
HEADLINE_LENGTH_MAX = 19  # ä»Šæ—¥å¤´æ¡æœ€é•¿è§†è§‰å®½åº¦ï¼ˆä¸­æ–‡å­—æ•°ï¼‰
HEADLINE_LEN_MAX = 25     # ä»Šæ—¥å¤´æ¡æ¯æ¡çš„å­—ç¬¦æ•°ç¡¬ä¸Šé™
SUMMARY_LENGTH_MIN = 45   # æ·±åº¦ä¸“é¢˜æ‘˜è¦æœ€çŸ­è§†è§‰å®½åº¦ï¼ˆä¸­æ–‡å­—æ•°ï¼‰
SUMMARY_LENGTH_MAX = 60   # æ·±åº¦ä¸“é¢˜æ‘˜è¦æœ€é•¿è§†è§‰å®½åº¦ï¼ˆä¸­æ–‡å­—æ•°ï¼‰
SUMMARY_LEN_MAX = 65      # æ·±åº¦ä¸“é¢˜æ‘˜è¦çš„å­—ç¬¦æ•°ç¡¬ä¸Šé™
HEADLINE_COUNT = 10    # ä»Šæ—¥å¤´æ¡æ¡æ•°
CLUSTER_ITEM_COUNT = 5 # æ¯ä¸ªä¸“é¢˜æ¿å—çš„æ–°é—»æ¡æ•°

# --- æŒ‰èµ›é“é…ç½®ä¸åŒçš„æ·±åº¦ä¸“é¢˜æ¿å— ---
CATEGORY_CLUSTERS = {
    "AI": [
        ("äº§å“", "æ–°äº§å“å‘å¸ƒã€äº§å“æ›´æ–°ã€åŠŸèƒ½è¿­ä»£"),
        ("æ¨¡å‹", "AIæ¨¡å‹ã€ç®—æ³•ã€æŠ€æœ¯çªç ´"),
        ("ç¡¬ä»¶ä¸ç®—åŠ›", "èŠ¯ç‰‡ã€GPUã€æœåŠ¡å™¨ã€äº‘è®¡ç®—ã€ç®—åŠ›åŸºå»º"),
        ("æŠ•èèµ„ä¸æ”¿ç­–", "èèµ„ã€æ”¶è´­ã€ä¸Šå¸‚ã€æ”¿ç­–æ³•è§„ã€è¡Œä¸šç›‘ç®¡"),
    ],
    "GAMES": [
        ("äº§å“", "æ–°æ¸¸å‘å¸ƒã€ç‰ˆæœ¬æ›´æ–°ã€DLCã€è¯„æµ‹"),
        ("ç”Ÿæ€", "ç”µç«èµ›äº‹ã€ä¸»æ’­ã€ç©å®¶ç¤¾åŒºã€æ¸¸æˆæ–‡åŒ–"),
        ("å•†ä¸š", "å‚å•†è´¢æŠ¥ã€æ”¶è´­å¹¶è´­ã€è£å‘˜ã€æ”¿ç­–ç›‘ç®¡"),
    ],
    "MUSIC": [
        ("äº§å“", "æ–°æ­Œã€æ–°ä¸“è¾‘ã€MVã€æ¦œå•æ•°æ®"),
        ("ç”Ÿæ€", "æ¼”å”±ä¼šã€éŸ³ä¹èŠ‚ã€è‰ºäººåŠ¨æ€ã€å‚ç‰Œç­¾çº¦"),
        ("å•†ä¸š", "ç‰ˆæƒäº¤æ˜“ã€æµåª’ä½“å¹³å°ã€èèµ„ã€è¡Œä¸šæ”¿ç­–"),
    ],
}

# --- Pydantic Data Models (ç”¨äº Writer ç»“æ„åŒ–è¾“å‡º) ---
class TopHeadline(BaseModel):
    title: str = Field(..., description=f"ä¸€å¥è¯çƒ­ç‚¹æ€»ç»“, è§†è§‰å®½åº¦æ§åˆ¶åœ¨{HEADLINE_LENGTH_MIN}-{HEADLINE_LENGTH_MAX}ä¸ªä¸­æ–‡å­—ä¹‹é—´")
    url: str = Field(..., description="å¯¹åº”æ–°é—»çš„åŸæ–‡é“¾æ¥")

class NewsItem(BaseModel):
    summary: str = Field(..., description=f"æ–°é—»æ‘˜è¦, è§†è§‰å®½åº¦æ§åˆ¶åœ¨{SUMMARY_LENGTH_MIN}-{SUMMARY_LENGTH_MAX}ä¸ªä¸­æ–‡å­—ä¹‹é—´")
    url: str = Field(..., description="åŸæ–‡é“¾æ¥")

class NewsCluster(BaseModel):
    name: str = Field(..., description="æ¿å—åç§°, æ ¹æ®èµ›é“ä¸åŒè€Œä¸åŒ")
    items: List[NewsItem] = Field(..., description=f"è¯¥æ¿å—ä¸‹çš„æ–°é—»åˆ—è¡¨, çº¦{CLUSTER_ITEM_COUNT}æ¡")

class NewsBriefing(BaseModel):
    headlines: List[TopHeadline] = Field(..., description=f"ä»Šæ—¥å¤´æ¡, çº¦{HEADLINE_COUNT}æ¡æœ€é‡è¦çš„çƒ­ç‚¹æ–°é—»")
    clusters: List[NewsCluster] = Field(..., description="æ·±åº¦ä¸“é¢˜åˆ†ç±»æ¿å—")

# --- Agent State ---
class AgentState(TypedDict):
    # æ¶ˆæ¯å†å²
    messages: List[BaseMessage]
    user_id: str
    message_id: Optional[str]
    user_preference: Optional[str]
    news_content: Optional[str] 
    
    # [æ–°å¢] ç»“æ„åŒ–ç®€æŠ¥æ•°æ® (ç”¨äºå¤šè½®å›å¿†)
    briefing_data: Optional[Dict] # å®é™…å­˜çš„æ˜¯ NewsBriefing.model_dump()
    generated_at: Optional[str]
    
    # [æ–°å¢] å½“å‰é€‰ä¸­çš„è¯¦æƒ…æ¿å— (ä¸ user_preference é•¿æœŸåå¥½åŒºåˆ†å¼€)
    selected_cluster: Optional[str]
    selected_category: Optional[str]

    # æ§åˆ¶æµæ ‡å¿—
    intent: Optional[str] # write / read / chat
    force_refresh: Optional[bool] # [æ–°å¢] æ˜¯å¦å¼ºåˆ¶åˆ·æ–°


class RouterDecision(BaseModel):
    """Router å¯¹ç”¨æˆ·æ„å›¾çš„åˆ†æç»“æœ"""
    intent: Literal["write", "read", "chat"] = Field(
        ..., description="ç”¨æˆ·çš„æ ¸å¿ƒæ„å›¾"
    )
    category: Optional[str] = Field(
        None, description="æå–å‡ºçš„å…·ä½“é¢†åŸŸå…³é”®è¯ï¼Œå¦‚ 'AI', 'ç§‘æŠ€'"
    )

from tools import fetch_news
from simple_bot import llm_fast, llm_reasoning # Import capability-based LLMs
import json

from langchain_core.prompts import ChatPromptTemplate

def router_node(state: AgentState):
    """
    è¿›é˜¶ç‰ˆæ„å›¾è¯†åˆ«ï¼šä½¿ç”¨ LLM ç»“æ„åŒ–è¾“å‡º + å®¹é”™å…œåº•
    
    æ–°å¢ï¼šå¦‚æœ state ä¸­å·²æœ‰ user_preferenceï¼ˆå®šæ—¶ä»»åŠ¡ä¼ å…¥ï¼‰ï¼Œç›´æ¥è¿”å› read æ„å›¾ï¼Œè·³è¿‡ LLM è§£æ
    """
    # --- æ‹¦æˆªå™¨ 0: å®šæ—¶ä»»åŠ¡ç»•è¡Œé€šé“ (scheduler ä¸“ç”¨) ---
    if state.get("user_preference"):
        print(f"âš¡ [Router] Scheduler mode detected, preference={state['user_preference']}, skipping LLM")
        return {"intent": "read"}  # ç›´æ¥è¿”å› read æ„å›¾ï¼Œuser_preference ä¿æŒä¸å˜
    
    last_message = state["messages"][-1].content
    print(f"ğŸš¦ Router handling message: {last_message}")
    
    # --- æ‹¦æˆªå™¨ 1: è¯¦æƒ…å±•å¼€æŒ‡ä»¤ (æ¥è‡ªå¡ç‰‡æŒ‰é’®) ---
    # åŒ¹é… "å±•å¼€ï¼šXXX" æˆ– "ğŸ‘‰ XXX"
    if "å±•å¼€ï¼š" in last_message or "ğŸ‘‰" in last_message:
        # ç®€å•ç²—æš´æå–ï¼šå–å†’å·æˆ–ç¬¦å·åçš„å†…å®¹ï¼Œå»é™¤æ‹¬å·é‡Œçš„æ•°å­—
        # e.g. "ğŸ‘‰ ç¡¬ä»¶ä¸ç®—åŠ› (8)" -> "ç¡¬ä»¶ä¸ç®—åŠ›"
        import re
        # åŒ¹é… "å±•å¼€ï¼š(.+)" æˆ– "ğŸ‘‰ (.+)"
        match = re.search(r"(?:å±•å¼€ï¼š|ğŸ‘‰\s*)([^\(\)]+)", last_message)
        if match:
            category = match.group(1).strip()
            print(f"ğŸš€ [Router] Intercepted Detail Request: {category}")
            return {
                "intent": "detail",
                "selected_cluster": category,
                "selected_category": state.get("selected_category"),
            }
    
    try:
        # å®šä¹‰ System Prompt å¼ºåŒ–æŒ‡ä»¤ (é€‚é… Reasoning æ¨¡å‹)
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ„å›¾è·¯ç”±å™¨ã€‚è¯·åˆ†æç”¨æˆ·çš„è¾“å…¥ï¼Œæå–æ ¸å¿ƒæ„å›¾å’Œå®ä½“ã€‚
        
        è§„åˆ™ï¼š
        1. å¦‚æœç”¨æˆ·æƒ³çœ‹æ–°é—»ã€æ—¥æŠ¥ã€ç®€æŠ¥ -> intent: read
        2. å¦‚æœç”¨æˆ·æƒ³è®¢é˜…ã€å…³æ³¨ã€è¿½è¸ªæŸè¯é¢˜ -> intent: write, category: <è¯é¢˜>
        3. å…¶ä»–æƒ…å†µï¼ˆé—²èŠã€é—®å¥½ã€ä¸æƒ³çœ‹äº†ï¼‰ -> intent: chat
        
        è¾“å‡ºæ ¼å¼ï¼šå¿…é¡»æ˜¯ç¬¦åˆ RouterDecision ç»“æ„çš„ JSONã€‚"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}"),
        ])
        
        # ç»‘å®šå·¥å…· (ä½¿ç”¨ Fast æ¨¡å‹ -> DeepSeek V3)
        print(f"ğŸ¤– User Input: {last_message}")
        structured_llm = llm_fast.with_structured_output(RouterDecision) 
        
        # ç»„åˆ chain
        # chain = prompt | structured_llm
        prompt_message = prompt.invoke({"input": last_message})
        decision = structured_llm.invoke(prompt_message)
        
        print(f"ğŸ‘‰ LLM Decision: {decision.intent}, Category: {decision.category}")
        return {
            "intent": decision.intent, 
            "user_preference": decision.category
        }
    except Exception as e:
        print(f"âš ï¸ Router LLM Error: {e}")
        # å…œåº•ç­–ç•¥ï¼šè¯šå®æŠ¥é”™ï¼Œä¸è¿›è¡ŒçŒœæµ‹
        return {
            "intent": "error",
            "messages": [AIMessage(content=f"âŒ æ„å›¾è¯†åˆ«å¤±è´¥å•¦ã€‚\né”™è¯¯è¯¦æƒ…: {str(e)}")]
        }


from database import upsert_preference, get_preference
from langchain_core.messages import AIMessage

def saver_node(state: AgentState):
    """ä¿å­˜ç”¨æˆ·åå¥½èŠ‚ç‚¹"""
    # 1. ä¼˜å…ˆä½¿ç”¨ Router æå–çš„ç»“æ„åŒ–æ•°æ®
    extracted_category = state.get("user_preference")
    
    # 2. å¦‚æœ Router æ²¡æå‡ºæ¥ï¼Œè¯šå®åœ°è¿”å›é”™è¯¯æç¤ºï¼Œè€Œä¸æ˜¯ççŒœ
    if not extracted_category:
        print("âš ï¸ [Saver] Extraction failed")
        return {"messages": [AIMessage(content="ğŸ¤” æˆ‘çŸ¥é“æ‚¨æƒ³è°ƒæ•´åå¥½ï¼Œä½†æˆ‘æ²¡èƒ½è¯†åˆ«å‡ºå…·ä½“çš„è¯é¢˜ã€‚\n\nè¯·å°è¯•æ›´æ¸…æ™°çš„æŒ‡ä»¤ï¼Œä¾‹å¦‚ï¼šâ€œè®¢é˜…AIâ€ã€â€œå…³æ³¨æ¸¸æˆGAMESâ€ã€â€œå…³æ³¨éŸ³ä¹MUSICâ€ã€‚")]}
    
    print(f"ğŸ’¾ [Saver] Saving preference: {extracted_category}")
    
    # 3. å­˜å…¥æ•°æ®åº“
    res = upsert_preference(state["user_id"], extracted_category)
    
    # 4. è¿”å›åŠ¨æ€æ¶ˆæ¯
    return {"messages": [AIMessage(content=f"å·²å…³æ³¨ï¼šã€{extracted_category}ã€‘æ¿å—ï¼Œæ¯æ—¥è‡ªåŠ¨ä¸ºæ‚¨æ¨é€\n\nç‚¹å‡»â€œå½“æ—¥{extracted_category}æ–°é—»â€ï¼Œå³å¯è·å–ä»Šæ—¥åŠ¨æ€ã€‚")]}



def fetcher_node(state: AgentState):
    """
    è´Ÿè´£è·å–æ–°é—»æ•°æ®ï¼š
    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. ã€å®šæ—¶ä»»åŠ¡æ¨¡å¼ã€‘state ä¸­å·²æœ‰ user_preferenceï¼ˆç›´æ¥ä» config ä¼ å…¥ï¼‰â†’ ä½¿ç”¨è¯¥å€¼
    2. ã€ç”¨æˆ·äº¤äº’æ¨¡å¼ã€‘state ä¸­æ—  user_preference â†’ ä»æ•°æ®åº“æŸ¥è¯¢ç”¨æˆ·è®¢é˜…åå¥½
    
    ç„¶åæ£€æŸ¥ç¼“å­˜æˆ–æŠ“å–æ–°é—»ï¼š
    - å…ˆæ£€æŸ¥æ•°æ®åº“ç¼“å­˜ (é™¤é force_refresh=True)
    - å¦‚æœæ— ç¼“å­˜ï¼Œè°ƒç”¨ Tool æŠ“å– RSS
    """
    print("ğŸ•µï¸ [Fetcher] Node started")
    
    # ç­–ç•¥ 1: ä¼˜å…ˆä½¿ç”¨ State ä¸­å·²å­˜åœ¨çš„ user_preferenceï¼ˆå®šæ—¶ä»»åŠ¡ä¼ å…¥ï¼‰
    pref = state.get("user_preference")
    
    # ç­–ç•¥ 2: å¦‚æœ State ä¸­æ²¡æœ‰ï¼Œåˆ™ä»æ•°æ®åº“æŸ¥è¯¢ï¼ˆç”¨æˆ·äº¤äº’åœºæ™¯ï¼‰
    if not pref:
        print("ğŸ” [Fetcher] No preference in state, querying database...")
        pref = get_preference(state["user_id"])
    else:
        print(f"âœ… [Fetcher] Using preference from state: {pref}")
    
    # ç­–ç•¥ 3: å¦‚æœä¸¤è€…éƒ½æ²¡æœ‰ï¼Œè¿”å›æç¤º
    if not pref:
        print("âš ï¸ [Fetcher] No preference found in state or database")
        return {
            "user_preference": None, 
            "messages": [AIMessage(content="æ‚¨è¿˜æ²¡æœ‰è®¢é˜…ä»»ä½•å†…å®¹ï¼Œè¯·å‘é€ 'è®¢é˜… AI'ï¼Œ'è®¢é˜… MUSIC'ï¼Œæˆ–è€…'è®¢é˜… GAMES'")]
        }
    
    # 1. å°è¯•ä»æ•°æ®åº“è¯»å–ä»Šæ—¥å·²ç”Ÿæˆçš„ç¼“å­˜
    today = date.today().isoformat()
    # æ³¨æ„ï¼šget_cached_news è¿”å› {"content": str, "briefing_data": str/json, "generated_at": str}
    
    # ç­–ç•¥ï¼šå¦‚æœæœ‰ç¼“å­˜ä¸”éå¼ºåˆ¶åˆ·æ–°ï¼Œæˆ‘ä»¬ç›´æ¥è¿”å›ç¼“å­˜
    if not state.get("force_refresh"):
        cached = get_cached_news(pref, today)
        if cached and cached.get("briefing_data"):
            print(f"âœ… [Fetcher] Found cached data for {pref}. generated_at={cached.get('generated_at')}")
            try:
                briefing_json = json.loads(cached["briefing_data"])
                return {
                    "user_preference": pref, 
                    "news_content": None, 
                    "briefing_data": briefing_json,
                    "generated_at": cached.get("generated_at")
                }
            except Exception as e:
                print(f"âš ï¸ [Fetcher] Cache parse failed: {e}")
                pass
    else:
        print(f"ğŸ”„ [Fetcher] Force refresh enabled. Skipping cache check.")

    # 2. æ— ç¼“å­˜æˆ–å¼ºåˆ¶åˆ·æ–°ï¼Œæ‰§è¡Œå®æ—¶æŠ“å–
    # 2. æ— ç¼“å­˜æˆ–å¼ºåˆ¶åˆ·æ–°ï¼Œæ‰§è¡Œå®æ—¶æŠ“å–
    print(f"ğŸŒ [Fetcher] Fetching news for: {pref}")
    
    news_data = fetch_news(pref)
    
    print(f"âœ… [Fetcher] Got data (length: {len(str(news_data))})")
    # å…³é”®ï¼šå½“éœ€è¦é‡æ–°æŠ“å–æ—¶ï¼Œæ˜¾å¼æ¸…ç©ºæ—§ç»“æ„åŒ–ç»“æœï¼Œé¿å… writer å‘½ä¸­ checkpointer æ®‹ç•™ state
    return {
        "user_preference": pref,
        "news_content": json.dumps(news_data, ensure_ascii=False),
        "briefing_data": None,
        "generated_at": None,
        "selected_cluster": None,
    }

from messaging import reply_message

from lark_card_builder import build_cover_card

def writer_node(state: AgentState):
    """
    æ ¸å¿ƒå†™ä½œèŠ‚ç‚¹ï¼š
    1. æ¥æ”¶ Fetcher æŠ“å–åˆ°çš„åŸå§‹æ–°é—»æ•°æ®
    2. è°ƒç”¨ Reasoning LLM (DeepSeek R1) è¿›è¡Œæ·±åº¦åˆ†æ
    3. ç”Ÿæˆç»“æ„åŒ–ç®€æŠ¥ (Summary + Clusters)
    4. å°†ç»“æœå­˜å…¥ Stateï¼Œå¹¶æ¸²æŸ“é£ä¹¦å¡ç‰‡
    """
    print("âœï¸ [Writer] Node started")
    
    if state.get("message_id"):
        reply_message(state["message_id"], "âœï¸ AI æ­£åœ¨æ·±åº¦åˆ†ææ–°é—»æ•°æ®ï¼Œç”Ÿæˆäº¤äº’å¼æ—©æŠ¥...")
        
    news_json = state.get("news_content")
    category = state.get("user_preference", "æœªçŸ¥é¢†åŸŸ")
    
    # ç­–ç•¥ 0: ä»…åœ¨éå¼ºåˆ¶åˆ·æ–°æ—¶å…è®¸å¤ç”¨ State ä¸­çš„ briefing_data (æ¥è‡ª Cache)
    if (not state.get("force_refresh")) and state.get("briefing_data"):
        try:
            print(f"â© [Writer] Using cached briefing data for {category}")
            # Pydantic è¿˜åŸ
            briefing = NewsBriefing(**state["briefing_data"])
            
            # æ„å»ºå¡ç‰‡ (ä¼ å…¥ generated_at å’Œ category)
            card_content = build_cover_card(briefing, generated_at=state.get("generated_at"), category=category)
            
            return {
                "briefing_data": state["briefing_data"], 
                "messages": [AIMessage(content=card_content)]
            }
        except Exception as e:
            print(f"âš ï¸ [Writer] Failed to reuse cache: {e}, falling back to generation")
            # å¤±è´¥äº†åˆ™ç»§ç»­å¾€ä¸‹æ‰§è¡Œç”Ÿæˆé€»è¾‘
    
    # ç­–ç•¥ 1: å¦‚æœæ²¡æœ‰ News Content (è¿™ä¸åº”è¯¥å‘ç”Ÿï¼ŒFetcher åº”è¯¥å¤„ç†äº†)ï¼ŒæŠ¥é”™
    if not news_json:
        return {"messages": [AIMessage(content="æœªèƒ½è·å–æ–°é—»æ•°æ®")]}

    # åŠ¨æ€ç”Ÿæˆæ¿å—é…ç½®
    cluster_config = CATEGORY_CLUSTERS.get(category, CATEGORY_CLUSTERS["AI"])
    cluster_count = len(cluster_config)
    cluster_desc = "\n".join(f"         - **{name}**ï¼š{desc}" for name, desc in cluster_config)
        
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„è¡Œä¸šæƒ…æŠ¥åˆ†æå¸ˆã€‚ç”¨æˆ·çš„è®¢é˜…åå¥½æ˜¯ï¼š{category}ã€‚
    è¯·é˜…è¯»è¾“å…¥çš„æ–°é—» JSON æ•°æ®ï¼Œè¿ç”¨ä½ çš„ä¸“ä¸šæ´å¯ŸåŠ›ï¼Œè¿›è¡Œä»¥ä¸‹å¤„ç†ï¼š

    1. **å»é‡ä¸æ¸…æ´—**ï¼šåˆå¹¶é›·åŒæ–°é—»ï¼Œå‰”é™¤æ— å…³å™ªéŸ³ã€‚

    2. **ä»Šæ—¥å¤´æ¡ (headlines)**ï¼š
       - ä»æ‰€æœ‰æ–°é—»ä¸­æç‚¼å‡ºæœ€é‡è¦çš„ **{HEADLINE_COUNT} æ¡** çƒ­ç‚¹
       - æ¯æ¡çƒ­ç‚¹ç”¨ **ä¸€å¥è¯æ€»ç»“**ï¼ŒæŒ‰è§†è§‰å®½åº¦å°½é‡æ§åˆ¶é•¿åº¦ï¼š**1ä¸ªä¸­æ–‡å­— = 2ä¸ªè‹±æ–‡å­—æ¯/æ•°å­—**ï¼Œæ€»è§†è§‰å®½åº¦å¿…é¡»åœ¨ **{HEADLINE_LENGTH_MIN}~{HEADLINE_LENGTH_MAX}ä¸ªä¸­æ–‡å­—** ä¹‹é—´ï¼Œä¸”æ€»å­—ç¬¦æ•°ï¼ˆä¸­è‹±æ–‡åŠ åœ¨ä¸€èµ·ï¼‰**ä¸å¾—è¶…è¿‡{HEADLINE_LEN_MAX}ä¸ª**
       - æ–‡å­—è¦ **çŠ€åˆ©ã€å…·ä½“ã€ç›´å‡»è¦å®³**ï¼Œå¿…é¡»æåŠå…·ä½“å…¬å¸åã€äº§å“åæˆ–å…³é”®æ•°æ®
       - æ ‡é¢˜è¦ **æœ‰å¸å¼•åŠ›**ï¼Œèƒ½è®©äººä¸€çœ¼çœ‹å‡ºæ–°é—»çš„ä»·å€¼
       - æ¯æ¡å¿…é¡»é™„å¸¦å¯¹åº”æ–°é—»çš„åŸæ–‡ URL
       - **ç¦æ­¢**ï¼šå¥—è¯ã€åºŸè¯ã€ç¬¼ç»Ÿæè¿°

    3. **æ·±åº¦ä¸“é¢˜ (clusters)**ï¼š
       - å°†æ–°é—» **å›ºå®š** å½’ç±»åˆ°ä»¥ä¸‹ {cluster_count} ä¸ªæ¿å—ï¼ˆå³ä½¿æŸä¸ªæ¿å—æš‚æ— æ–°é—»ï¼Œä¹Ÿä¿ç•™ç©ºåˆ—è¡¨ï¼‰ï¼š
{cluster_desc}
       - æ¯ä¸ªæ¿å—çº¦ **{CLUSTER_ITEM_COUNT} æ¡** æ–°é—»æ‘˜è¦
       - æ¯æ¡æ‘˜è¦è¦ **æœ‰å¸å¼•åŠ›**ï¼Œèƒ½è®©äººä¸€çœ¼çœ‹å‡ºæ–°é—»çš„ä»·å€¼
       - æ¯æ¡æ‘˜è¦ä»…å¯èƒ½å°è¯•æŒ‰ç…§ä¸‰å°å¥çš„æ ¼å¼è¿›è¡Œå†™ä½œï¼šå‘ç”Ÿäº†ä»€ä¹ˆï¼Œç»†èŠ‚è¡¥å……æè¿°ï¼Œæœ‰ä»€ä¹ˆå½±å“
       - æ¯æ¡æ‘˜è¦æŒ‰è§†è§‰å®½åº¦å°½é‡æ§åˆ¶é•¿åº¦ï¼š**1ä¸ªä¸­æ–‡å­— = 2ä¸ªè‹±æ–‡å­—æ¯/æ•°å­—**ï¼Œæ€»è§†è§‰å®½åº¦å¿…é¡»åœ¨ **{SUMMARY_LENGTH_MIN}~{SUMMARY_LENGTH_MAX}ä¸ªä¸­æ–‡å­—** ä¹‹é—´ï¼Œä¸”æ€»å­—ç¬¦æ•°ï¼ˆä¸­è‹±æ–‡åŠ åœ¨ä¸€èµ·ï¼‰**ä¸å¾—è¶…è¿‡{SUMMARY_LEN_MAX}ä¸ª**ï¼Œä¿¡æ¯å¯†åº¦é«˜ï¼Œç›´å‡»æ ¸å¿ƒ
       - æ¯æ¡å¿…é¡»é™„å¸¦å¯¹åº”æ–°é—»çš„åŸæ–‡ URL
    
    è¯·ä¸¥æ ¼è¾“å‡ºç¬¦åˆ NewsBriefing ç»“æ„çš„ JSONã€‚
    **é‡è¦**ï¼š
    1. ç›´æ¥è¾“å‡º JSON å­—ç¬¦ä¸²ï¼Œ**ä¸è¦**åŒ…å« ```json ... ``` ç­‰ Markdown æ ¼å¼ã€‚
    2. JSON æ ¹å¯¹è±¡ç›´æ¥åŒ…å« `headlines` å’Œ `clusters` å­—æ®µï¼Œ**ä¸è¦**åŒ…è£¹åœ¨ `NewsBriefing` ç­‰æ ¹é”®ä¸‹ã€‚
    3. ä¸è¦åŒ…å«ä»»ä½•æ¨ç†è¿‡ç¨‹æ–‡æœ¬ã€‚
    4. æ‰€æœ‰æ€»ç»“æ€§æ–‡å­—ï¼ˆheadlines çš„ title å’Œ clusters items çš„ summaryï¼‰çš„å¥æœ« **ä¸è¦åŠ å¥å·**ï¼ˆã€‚ï¼‰ï¼Œä¿æŒç®€æ´å¹²ç»ƒã€‚"""
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{news_data}"),
    ])
    
    print("ğŸ§  [Writer] Invoking LLM for Structured Output...")
    # åˆ‡æ¢åˆ° llm_reasoning (Claude 3.5 Sonnet / DeepSeek R1) ä»¥è·å¾—æœ€ä½³å†™ä½œè´¨é‡
    structured_llm = llm_reasoning.with_structured_output(NewsBriefing) 
    chain = prompt | structured_llm
    
    try:
        briefing: NewsBriefing = chain.invoke({"news_data": news_json})
        print(f"âœ… [Writer] Briefing Generated. Clusters: {[c.name for c in briefing.clusters]}")
        
        # 1. æ„å»ºé£ä¹¦äº¤äº’å¡ç‰‡
        card_content = build_cover_card(briefing, category=category)
        
        # 2. è¿”å›ç»“æœ
        # æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦æ ‡è®°è¿™æ˜¯ä¸€å¼ å¡ç‰‡ï¼Œè€Œä¸æ˜¯æ™®é€šæ–‡æœ¬
        # ä¸‹æ¸¸å‘é€ç«¯ (lark_service æˆ– messaging) éœ€è¦è¯†åˆ«è¿™ä¸ªæ ‡è®°
        # è¿™é‡Œæˆ‘ä»¬å°† content è®¾ä¸º card jsonï¼Œå¼€å¤´åŠ ä¸€ä¸ªç‰¹æ®Šæ ‡è®°ï¼Ÿ
        # æˆ–è€…ä½¿ç”¨ additional_kwargs
        
        return {
            "briefing_data": briefing.model_dump(),
            "messages": [AIMessage(content=card_content)] 
        }
    except Exception as e:
        print(f"âŒ [Writer] Analysis Failed: {e}")
        return {"messages": [AIMessage(content=f"ç”Ÿæˆæ—©æŠ¥å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚\nError: {str(e)}")]}


# --- è¯¦æƒ…å±•ç¤ºèŠ‚ç‚¹ ---

from database import get_cached_news # Import at top or inside if circular
from datetime import date

# --- è¯¦æƒ…å±•ç¤ºèŠ‚ç‚¹ ---
def detail_node(state: AgentState):
    """
    æ¥æ”¶ç”¨æˆ·é€‰æ‹©çš„æ¿å—å -> ä» State ç¼“å­˜æˆ–æ•°æ®åº“ä¸­æŸ¥æ‰¾æ–°é—» -> æ¸²æŸ“è¯¦æƒ…
    """
    print("ğŸ” [Detail] Node started")
    target_cluster = state.get("selected_cluster")
    selected_category = state.get("selected_category")
    print(
        f"ğŸ” [Detail] target_cluster={target_cluster}, "
        f"selected_category={selected_category}, resolved_category=None"
    )

    if not target_cluster:
        return {"messages": [AIMessage(content="âš ï¸ æœªæŒ‡å®šè¦å±•å¼€çš„ä¸“é¢˜ï¼Œè¯·é‡æ–°ç‚¹å‡»å¡ç‰‡æŒ‰é’®")]}

    if not selected_category:
        return {
            "messages": [
                AIMessage(
                    content="å½“å‰å¡ç‰‡ç‰ˆæœ¬è¾ƒæ—§ï¼Œç¼ºå°‘ç±»åˆ«ä¿¡æ¯ã€‚è¯·å…ˆé‡æ–°ç”Ÿæˆæ—¥æŠ¥å¡ç‰‡åå†å±•å¼€ä¸“é¢˜ã€‚"
                )
            ]
        }

    today = date.today().isoformat()
    cached = get_cached_news(selected_category, today)
    if not cached or not cached.get("briefing_data"):
        return {
            "messages": [
                AIMessage(
                    content=f"âš ï¸ æœªæ‰¾åˆ° {selected_category} ä»Šæ—¥ç¼“å­˜ã€‚\n\nè¯·å…ˆé‡æ–°ç”Ÿæˆè¯¥ç±»åˆ«æ—¥æŠ¥åå†å±•å¼€ä¸“é¢˜ã€‚"
                )
            ]
        }

    try:
        briefing_dump = json.loads(cached["briefing_data"])
        briefing = NewsBriefing(**briefing_dump)
    except Exception as e:
        print(f"âš ï¸ [Detail] Parse cache failed for category={selected_category}: {e}")
        return {"messages": [AIMessage(content="âš ï¸ æ•°æ®è§£æé”™è¯¯")]}

    # ä»…åšç²¾ç¡®åŒ¹é…ï¼Œé¿å…åŒåä¸“é¢˜ä¸²åˆ°å…¶ä»–ç±»åˆ«
    found_cluster = None
    for cluster in briefing.clusters:
        if cluster.name == target_cluster:
            found_cluster = cluster
            break

    if not found_cluster:
        return {
            "messages": [
                AIMessage(content=f"âš ï¸ åœ¨ {selected_category} ç±»åˆ«ä¸‹æœªæ‰¾åˆ°ä¸“é¢˜ï¼š{target_cluster}")
            ]
        }

    print(
        f"âœ… [Detail] target_cluster={target_cluster}, "
        f"selected_category={selected_category}, resolved_category={selected_category}"
    )
        
    # æ¸²æŸ“è¯¦æƒ…ï¼šæ¯æ¡æ–°é—»çš„æ‘˜è¦æœ¬èº«å°±æ˜¯è¶…é“¾æ¥
    msg = f"## ğŸ“‚ ä¸“é¢˜è¯¦æƒ…ï¼š{found_cluster.name}\n\n"
    for i, item in enumerate(found_cluster.items, 1):
        msg += f"{i}. [{item.summary}]({item.url})\n"
    
    return {"messages": [AIMessage(content=msg)]}



# --- ç»„è£…å›¾è°± (The Map) ---
from langgraph.graph import StateGraph, END

# 1. æ‹¿å‡ºä¸€å¼ ç©ºç™½åœ°å›¾
workflow = StateGraph(AgentState)

# Chat Node: ä½¿ç”¨ LLM è¿›è¡Œè‡ªç„¶å¯¹è¯
def chat_node(state):
    """èŠå¤©æ¨¡å¼èŠ‚ç‚¹ - è°ƒç”¨ LLM è¿›è¡Œå¤šè½®å¯¹è¯"""
    # state["messages"] å·²åŒ…å«å†å²ä¸Šä¸‹æ–‡ï¼ˆç”± run_agent çš„æ»‘åŠ¨çª—å£æä¾›ï¼‰
    response = llm_fast.invoke(state["messages"])
    return {"messages": [response]}

# 2. åœ¨åœ°å›¾ä¸Šç”»ç«™ç‚¹ (Nodes)
workflow.add_node("router", router_node)
workflow.add_node("saver", saver_node)
workflow.add_node("fetcher", fetcher_node)
workflow.add_node("writer", writer_node)
workflow.add_node("detail", detail_node) # æ–°å¢ Detail èŠ‚ç‚¹
workflow.add_node("chat", chat_node)

# 3. è®¾ç½®èµ·ç‚¹
workflow.set_entry_point("router")

# 4. è®¾ç½®åˆ†å²”è·¯å£
workflow.add_conditional_edges(
    "router",
    lambda x: x["intent"],
    {
        "write": "saver",
        "read": "fetcher",
        "detail": "detail", 
        "chat": "chat",
        "error": END
    }
)

# 5. è®¾ç½®ç»ˆç‚¹
workflow.add_edge("saver", END)
workflow.add_edge("chat", END)
workflow.add_edge("fetcher", "writer")
workflow.add_edge("writer", END)
workflow.add_edge("detail", END) # Detail -> END

# 6. ç¼–è¯‘ï¼ˆå¯ç”¨ Checkpointer ä»¥æŒä¹…åŒ– Stateï¼‰
from langgraph.checkpoint.memory import MemorySaver
memory = MemorySaver()
graph = workflow.compile(checkpointer=memory)
