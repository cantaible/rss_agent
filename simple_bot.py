import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

load_dotenv()

# åˆå§‹åŒ–ä¸€ä¸ªå…¨å±€çš„ ChatOpenAI å®ä¾‹ï¼Œé¿å…æ¯æ¬¡è°ƒç”¨éƒ½é‡æ–°è¿æ¥
llm = ChatOpenAI(
    model=os.getenv("LLM_MODEL_NAME"),
    openai_api_base=os.getenv("OPENAI_API_BASE"),
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

def get_bot_response(user_input: str) -> str:
    """
    æ ¸å¿ƒå‡½æ•°ï¼šæ¥æ”¶ç”¨æˆ·æ–‡æœ¬ -> è°ƒç”¨å¤§æ¨¡å‹ -> è¿”å›å›å¤
    """
    try:
        response = llm.invoke(user_input)
        return response.content
    except Exception as e:
        return f"Sorry, AI brain error: {str(e)}"

def test_bot():
    print("ğŸ¤– Sending request to:", llm.model_name)
    print("âœ… Response:", get_bot_response("Hello!"))

if __name__ == "__main__":
    test_bot()
